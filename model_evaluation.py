# -*- coding: utf-8 -*-
"""Model Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mTshaB4NikFCXgK8UhY66aQgh3WzNr4u
"""

from google.colab import drive
drive.mount('/content/drive')

import os
notebook_path = os.path.abspath(".")
os.chdir('/content/drive/MyDrive/DLIP_FINAL')
print("현재 노트북 디렉토리 경로:", notebook_path)

!pip install piq

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torchvision import models
from torchsummary import summary
from torch.utils.data import DataLoader
import piq
import matplotlib.pyplot as plt
import torchvision.utils as vutils
import numpy as np

# Get cpu or gpu device for training.
device = "cuda" if torch.cuda.is_available() else "cpu"

print(f"Using {device} device")

if torch.cuda.is_available(): print(f'Device name: {torch.cuda.get_device_name(0)}')

transform_test = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    #transforms.Normalize(mean=[0.5], std=[0.5])
])

test_dataset=torchvision.datasets.ImageFolder(root='./final_dataset/test',transform=transform_test)
test_dataset.class_to_idx = {'good':0, 'anomaly':1}  # 원하는 매핑으로 재정의
test_loader=DataLoader(test_dataset,batch_size=4, shuffle=True)
test_dataset.samples = [
    (path, test_dataset.class_to_idx[os.path.basename(os.path.dirname(path))])
    for path, _ in test_dataset.samples
]

anomaly_test_dataset=torchvision.datasets.ImageFolder(root='./final_dataset/anomaly',transform=transform_test)
anomaly_test_dataset.class_to_idx = {'anomaly':1}  # 원하는 매핑으로 재정의
anomaly_test_loader=DataLoader(anomaly_test_dataset,batch_size=4, shuffle=True)
anomaly_test_dataset.samples = [
    (path, anomaly_test_dataset.class_to_idx[os.path.basename(os.path.dirname(path))])
    for path, _ in anomaly_test_dataset.samples
]

good_test_dataset=torchvision.datasets.ImageFolder(root='./final_dataset/good',transform=transform_test)
good_test_dataset.class_to_idx = {'good':0}  # 원하는 매핑으로 재정의
good_test_loader=DataLoader(good_test_dataset,batch_size=4, shuffle=True)
good_test_dataset.samples = [
    (path, good_test_dataset.class_to_idx[os.path.basename(os.path.dirname(path))])
    for path, _ in good_test_dataset.samples
]

class ConvAutoencoder(nn.Module):
    def __init__(self):
        super(ConvAutoencoder, self).__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),   # [B, 64, 256, 256]
            nn.ReLU(),
            nn.MaxPool2d(2, 2, padding=0),    # [B, 64, 128, 128]
            nn.Conv2d(64, 128, 3, padding=1), # [B, 128, 128, 128]
            nn.ReLU(),
            nn.MaxPool2d(2, 2, padding=0),    # [B, 128, 64, 64]
            nn.Conv2d(128, 256, 3, padding=1),# [B, 256, 64, 64]
            nn.ReLU(),
            nn.MaxPool2d(2, 2, padding=0)     # [B, 256, 32, 32]
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.Conv2d(256, 256, 3, padding=1),# [B, 256, 32, 32]
            nn.ReLU(),
            nn.Upsample(scale_factor=2),      # [B, 256, 64, 64]
            nn.Conv2d(256, 128, 3, padding=1),# [B, 128, 64, 64]
            nn.ReLU(),
            nn.Upsample(scale_factor=2),      # [B, 128, 128, 128]
            nn.Conv2d(128, 64, 3, padding=1), # [B, 64, 128, 128]
            nn.ReLU(),
            nn.Upsample(scale_factor=2),      # [B, 64, 256, 256]
            nn.Conv2d(64, 3, 3, padding=1),   # [B, 3, 256, 256]
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x


input_size=256

model=ConvAutoencoder().to(device)

summary(model,(3,input_size,input_size))

# 저장한 weight 불러오기
model.load_state_dict(torch.load('model.pth', map_location=device))

class HybridLoss(nn.Module):
  def __init__(self,alpha=0.8):
    super(HybridLoss,self).__init__()
    self.alpha=alpha
    self.mse=nn.MSELoss()

  def forward(self,recon,origin):

    ssim_loss=1-piq.ssim(recon,origin,data_range=1.0)
    mse_loss=self.mse(recon, origin)

    return self.alpha*mse_loss+(1-self.alpha)*ssim_loss


loss_fn=HybridLoss()

def evaluate_accuracy(model, dataloader, loss_fn, threshold=0.01):

    model.eval()
    all_errors = []
    all_labels = []
    all_preds = []
    correct = 0
    total = len(dataloader.dataset)

    total_mse = 0.0
    total_ssim = 0.0
    batch_count = 0

    with torch.no_grad():

      for inputs, labels in dataloader:
          inputs = inputs.to(device)
          labels = labels.to(device)
          outputs = model(inputs)

          # 재구성 에러 (MSE)
          reconstruction_error = F.mse_loss(outputs, inputs, reduction='none')
          reconstruction_error = reconstruction_error.mean(dim=[1,2,3])  # batch 단위 평균
          all_errors.extend(reconstruction_error.cpu().numpy())
          all_labels.extend(labels.cpu().numpy())




          # 예측: 오류가 threshold보다 크면 anomaly (1), 작으면 normal (0)
          preds = (reconstruction_error > threshold).float()
          all_preds.extend(preds.cpu().numpy())

          # normal=0, anomaly=1 라벨로 구성되어 있음
          correct += (preds == labels).sum().item()

          # 전체 평균 MSE
          batch_mse = F.mse_loss(outputs, inputs, reduction='mean').item()
          total_mse += batch_mse

          # 전체 평균 SSIM
          ssim_value = piq.ssim(outputs, inputs, data_range=1.0).item()
          total_ssim += ssim_value

          batch_count += 1


    acc = correct / total
    avg_mse = total_mse / batch_count
    avg_ssim = total_ssim / batch_count
    ssim_loss = 1 - avg_ssim
    print(f'✅ Test Accuracy: {acc * 100:.2f}% (Threshold: {threshold})\n')
    print(f'Average MSE: {avg_mse:.6f}')
    print(f'Average SSIM: {avg_ssim:.6f} (SSIM Loss: {ssim_loss:.6f})\n')

    return acc, all_errors, all_labels, all_preds

def plot_recon_error_histogram_from_evaluation(errors, labels):
    normal_errors = [e for e, l in zip(errors, labels) if l == 0]
    anomaly_errors = [e for e, l in zip(errors, labels) if l == 1]

    plt.figure(figsize=(8, 5))
    plt.hist(normal_errors, bins=50, alpha=0.6, label='Normal', color='blue')
    plt.hist(anomaly_errors, bins=50, alpha=0.6, label='Anomaly', color='red')
    plt.axvline(np.mean(normal_errors), color='blue', linestyle='dashed', label='Normal Mean')
    plt.axvline(np.mean(anomaly_errors), color='red', linestyle='dashed', label='Anomaly Mean')
    plt.title("Reconstruction Error Histogram")
    plt.xlabel("Reconstruction Error")
    plt.ylabel("Count")
    plt.legend()
    plt.grid(True)
    plt.show()

print("Testing only scratch dataset")
acc, all_errors, all_labels, preds = evaluate_accuracy(model, anomaly_test_loader, loss_fn, threshold=0.0011)

plt.figure(figsize=(8, 5))
plt.hist(all_errors, bins=30, color='red', edgecolor='white')
plt.title("Reconstruction Error Distribution (anomaly)")
plt.xlabel("Reconstruction Error")
plt.ylabel("Count")
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

print("Testing only good dataset")
acc, all_errors, all_labels, preds = evaluate_accuracy(model, good_test_loader, loss_fn, threshold=0.0011)

plt.figure(figsize=(8, 5))
plt.hist(all_errors, bins=30, color='mediumslateblue', edgecolor='white')
plt.title("Reconstruction Error Distribution (good)")
plt.xlabel("Reconstruction Error")
plt.ylabel("Count")
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

acc, errors, labels, preds = evaluate_accuracy(model, test_loader, loss_fn, threshold=0.0011)
plot_recon_error_histogram_from_evaluation(errors, labels)

def compute_confusion_counts(preds, labels):
    preds = np.array(preds).astype(int)
    labels = np.array(labels).astype(int)

    TP = np.sum((preds == 1) & (labels == 1))
    TN = np.sum((preds == 0) & (labels == 0))
    FP = np.sum((preds == 1) & (labels == 0))
    FN = np.sum((preds == 0) & (labels == 1))

    return TP, FN, FP, TN

from matplotlib.patches import Rectangle

def plot_confusion_map(TP, FN, FP, TN):
    fig, ax = plt.subplots(figsize=(6, 4))

    # 사각형 배경
    ax.add_patch(Rectangle((0, 1), 1, 1, facecolor='mediumseagreen'))  # TP
    ax.add_patch(Rectangle((1, 1), 1, 1, facecolor='cornflowerblue'))  # FN
    ax.add_patch(Rectangle((0, 0), 1, 1, facecolor='cornflowerblue'))  # FP
    ax.add_patch(Rectangle((1, 0), 1, 1, facecolor='mediumseagreen'))  # TN

    # 텍스트: 위치, 내용, 색상
    ax.text(0.5, 1.5, f'True Positives\nTP = {TP}', ha='center', va='center', fontsize=12, color='white')
    ax.text(1.5, 1.5, f'False Negatives\nFN = {FN}', ha='center', va='center', fontsize=12, color='white')
    ax.text(0.5, 0.5, f'False Positives\nFP = {FP}', ha='center', va='center', fontsize=12, color='white')
    ax.text(1.5, 0.5, f'True Negatives\nTN = {TN}', ha='center', va='center', fontsize=12, color='white')

    # 라벨
    ax.text(-0.3, 1, 'Actual', va='center', ha='center', rotation='vertical', fontsize=13)
    ax.text(1, 2.05, 'Predicted', ha='center', fontsize=13)

    # 선, 눈금 제거
    ax.set_xlim(0, 2)
    ax.set_ylim(0, 2)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_aspect('equal')
    ax.axis('off')

    plt.title("Confusion Matrix", fontsize=14, pad=20)
    plt.tight_layout()
    plt.show()

TP, FN, FP, TN = compute_confusion_counts(preds, labels)
plot_confusion_map(TP, FN, FP, TN)

Accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-6)
precision = TP / (TP + FP + 1e-6)
recall = TP / (TP + FN + 1e-6)
f1 = (2 * precision * recall) / (precision + recall + 1e-6)

print(f"Accuracy: {Accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall:    {recall:.3f}")
print(f"F1-score:  {f1:.3f}")

import matplotlib.pyplot as plt
import torch.nn.functional as F

def show_error_map(input_tensor, output_tensor, index=0, cmap='hot'):
    """
    input_tensor, output_tensor: shape [B, C, H, W] (normalized [0,1])
    index: 배치 중 시각화할 이미지 인덱스
    """
    # 1. MSE error map 계산
    with torch.no_grad():
        error_map = F.mse_loss(output_tensor, input_tensor, reduction='none')  # [B, C, H, W]
        error_map = error_map.mean(dim=1)  # [B, H, W]

    # 2. numpy로 변환
    input_img = input_tensor[index].permute(1, 2, 0).cpu().numpy()
    output_img = output_tensor[index].permute(1, 2, 0).cpu().numpy()
    error_img = error_map[index].cpu().numpy()

    # 3. 시각화
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(input_img)
    axs[0].set_title("Input Image")
    axs[0].axis('off')

    axs[1].imshow(output_img)
    axs[1].set_title("Reconstructed Image")
    axs[1].axis('off')

    axs[2].imshow(error_img, cmap=cmap)
    axs[2].set_title("Reconstruction Error Map")
    axs[2].axis('off')

    plt.tight_layout()
    plt.show()

with torch.no_grad():
    for inputs, _ in good_test_loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        show_error_map(inputs, outputs, index=0)  # 배치에서 0번째 이미지 시각화
        break  # 한 배치만 보고 싶으면 break

with torch.no_grad():
    for inputs, _ in anomaly_test_loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        show_error_map(inputs, outputs, index=0)  # 배치에서 0번째 이미지 시각화
        break  # 한 배치만 보고 싶으면 break

